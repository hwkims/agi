# ... (Python ë°±ì—”ë“œ ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼) ...
import fastapi
import uvicorn
from fastapi import WebSocket, WebSocketDisconnect, Response
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
import requests
import edge_tts
import asyncio
import base64
import os
import time
import json
import uuid
from pathlib import Path
import threading

# --- Configuration (ë³€ê²½ ì—†ìŒ) ---
MODEL_NAME = "gemma3:4b"
OLLAMA_API_URL = "http://localhost:11434/api/generate"
PERSONA_NAME = "Aura"
SYSTEM_CONTEXT = f"""You are {PERSONA_NAME}, an AI assistant observing the world through a webcam.
Keep responses concise (1-2 sentences), conversational, and related to the image and user text.
"""
TTS_VOICE = "ko-KR-SunHiNeural"
AUDIO_DIR = Path("static_audio")
AUDIO_DIR.mkdir(parents=True, exist_ok=True)

# --- Frontend Code (Embedded as Strings) ---

HTML_CONTENT = """
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aura - Webcam Companion</title>
    <link rel="stylesheet" href="/static/css/style.css">
</head>
<body>
    <h1>ğŸ“· Aura - ë‹¹ì‹ ì˜ ì›¹ìº  ì¹œêµ¬</h1>
    <div class="container">
        <div class="video-container">
            <h2>ì›¹ìº  í™”ë©´</h2>
            <video id="webcam" autoplay playsinline muted></video>
            <canvas id="canvas" style="display: none;"></canvas> <!-- í”„ë ˆì„ ìº¡ì²˜ìš© -->
            <div class="controls">
                <!-- ë²„íŠ¼ ìƒíƒœëŠ” JSì—ì„œ ì œì–´ -->
                <button id="connect-disconnect">ì„œë²„ ì—°ê²°</button> <!-- ì—°ê²°/í•´ì œ í† ê¸€ ë²„íŠ¼ -->
                <button id="start-stop-observe" disabled>ê´€ì°° ì‹œì‘</button> <!-- ê´€ì°° ì‹œì‘/ì¤‘ì§€ í† ê¸€ ë²„íŠ¼ -->
            </div>
            <p id="status-message" class="status-message">ìƒíƒœ: ì¤€ë¹„ë¨</p> <!-- ìƒíƒœ ë©”ì‹œì§€ í‘œì‹œ ì˜ì—­ -->
        </div>

        <div class="chat-container">
            <h2>Auraì™€ ëŒ€í™”í•˜ê¸°</h2>
            <div id="chatbox">
                <!-- ì±„íŒ… ë©”ì‹œì§€ê°€ ì—¬ê¸°ì— ì¶”ê°€ë©ë‹ˆë‹¤ -->
            </div>
            <div class="input-area">
                 <div id="stt-status" class="stt-status">STT ìƒíƒœ: ì¤€ë¹„ë¨</div>
                 <div class="input-controls">
                    <button id="start-stt" title="ë“£ê¸° ì‹œì‘" disabled>ğŸ¤</button> <!-- ì´ˆê¸° ë¹„í™œì„±í™” -->
                    <button id="stop-stt" title="ë“£ê¸° ì¤‘ì§€" disabled>â¹ï¸</button>
                    <input type="text" id="text-input" placeholder="Auraì—ê²Œ ë©”ì‹œì§€ ë³´ë‚´ê¸°..." disabled> <!-- ì´ˆê¸° ë¹„í™œì„±í™” -->
                    <button id="send-button" disabled>ì „ì†¡</button> <!-- ì´ˆê¸° ë¹„í™œì„±í™” -->
                 </div>
            </div>
        </div>
    </div>

    <!-- TTS ì¬ìƒìš© ì˜¤ë””ì˜¤ ìš”ì†Œ -->
    <audio id="tts-audio" style="display: none;"></audio>

    <script src="/static/js/main.js"></script>
</body>
</html>
"""

# ... (CSS_CONTENTëŠ” ì´ì „ê³¼ ë™ì¼) ...
CSS_CONTENT = """
body {
    font-family: sans-serif;
    margin: 20px;
    background-color: #f4f4f4;
    color: #333;
}

.container {
    display: flex;
    gap: 20px;
    flex-wrap: wrap; /* í™”ë©´ ì‘ì„ ë•Œ ì¤„ë°”ê¿ˆ */
}

.video-container, .chat-container {
    background-color: #fff;
    padding: 20px;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    flex: 1; /* ê°€ëŠ¥í•œ ê³µê°„ ì°¨ì§€ */
    min-width: 400px; /* ìµœì†Œ ë„ˆë¹„ */
    display: flex;
    flex-direction: column; /* ë‚´ë¶€ ìš”ì†Œ ì„¸ë¡œ ì •ë ¬ */
}

h1, h2 {
    color: #333;
    border-bottom: 1px solid #eee;
    padding-bottom: 10px;
    margin-top: 0;
}

#webcam {
    width: 100%;
    max-width: 640px; /* ìµœëŒ€ ë„ˆë¹„ ì œí•œ */
    height: auto;
    border: 1px solid #ccc;
    background-color: #000; /* ë¹„ë””ì˜¤ ë¡œë”© ì¤‘ ë°°ê²½ */
    display: block; /* ì•„ë˜ margin ì ìš© ìœ„í•´ */
    margin-bottom: 10px;
}

.controls {
    margin-top: 10px; /* ë¹„ë””ì˜¤ì™€ ê°„ê²© */
    display: flex;
    gap: 10px;
    align-items: center;
}

.status-message { /* ìƒíƒœ ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    margin-top: 10px;
    font-size: 0.9em;
    color: #555;
    font-style: italic;
}

button {
    padding: 8px 15px;
    cursor: pointer;
    border: none;
    border-radius: 4px;
    background-color: #007bff;
    color: white;
    font-size: 14px;
    transition: background-color 0.2s ease; /* ë¶€ë“œëŸ¬ìš´ ìƒ‰ìƒ ë³€ê²½ */
}

button:disabled {
    background-color: #ccc;
    cursor: not-allowed;
}

button:hover:not(:disabled) {
    background-color: #0056b3;
}

.chat-container {
    justify-content: space-between; /* ì œëª©/ì±„íŒ…ì°½ê³¼ ì…ë ¥ì°½ ë¶„ë¦¬ */
}

#chatbox {
    height: 400px; /* ì±„íŒ…ì°½ ë†’ì´ ê³ ì • */
    overflow-y: auto; /* ë‚´ìš© ë§ìœ¼ë©´ ìŠ¤í¬ë¡¤ */
    border: 1px solid #eee;
    padding: 10px;
    margin-bottom: 15px;
    background-color: #f9f9f9;
    flex-grow: 1; /* ë‚¨ëŠ” ì„¸ë¡œ ê³µê°„ ì°¨ì§€ */
}

.message {
    margin-bottom: 10px;
    padding: 8px 12px; /* íŒ¨ë”© ì¡°ì • */
    border-radius: 10px; /* ë” ë‘¥ê¸€ê²Œ */
    line-height: 1.4;
    max-width: 80%; /* ë©”ì‹œì§€ ìµœëŒ€ ë„ˆë¹„ */
    word-wrap: break-word; /* ê¸´ ë‹¨ì–´ ì¤„ë°”ê¿ˆ */
}

.message.system {
    font-style: italic;
    color: #666;
    background-color: #efefef;
    text-align: center;
    max-width: 100%;
}

.message.user {
    background-color: #007bff; /* ì‚¬ìš©ì ë©”ì‹œì§€ ë°°ê²½ */
    color: white;
    margin-left: auto; /* ì˜¤ë¥¸ìª½ ì •ë ¬ */
    border-bottom-right-radius: 0; /* ë§í’ì„  ê¼¬ë¦¬ íš¨ê³¼ */
}

.message.aura {
    background-color: #e9ecef; /* AI ë©”ì‹œì§€ ë°°ê²½ */
    color: #333;
    margin-right: auto; /* ì™¼ìª½ ì •ë ¬ */
    border-bottom-left-radius: 0; /* ë§í’ì„  ê¼¬ë¦¬ íš¨ê³¼ */
}

.message strong {
    /* ë°œì‹ ì ì´ë¦„ ìˆ¨ê¹€ (CSSë¡œ ì²˜ë¦¬) */
    display: none;
}


.input-area {
     border-top: 1px solid #eee;
     padding-top: 15px;
     margin-top: auto; /* í•­ìƒ ì•„ë˜ì— ìœ„ì¹˜ */
}

.stt-status {
    font-size: 0.9em;
    color: #555;
    margin-bottom: 10px;
    min-height: 1.2em; /* ë†’ì´ ê³ ì • */
    text-align: center;
}

.input-controls {
    display: flex;
    gap: 10px;
    align-items: center;
}

#text-input {
    flex-grow: 1; /* ë‚¨ëŠ” ê³µê°„ ëª¨ë‘ ì°¨ì§€ */
    padding: 10px;
    border: 1px solid #ccc;
    border-radius: 20px; /* ë‘¥ê·¼ ì…ë ¥ì°½ */
    outline: none; /* í¬ì»¤ìŠ¤ ì‹œ í…Œë‘ë¦¬ ì œê±° */
}
#text-input:focus {
    border-color: #007bff;
    box-shadow: 0 0 0 2px rgba(0, 123, 255, 0.25);
}

#start-stt, #stop-stt {
    background-color: #6c757d;
    border-radius: 50%; /* ë™ê·¸ë€ ë²„íŠ¼ */
    width: 40px;
    height: 40px;
    font-size: 18px;
    padding: 0;
    display: flex;
    justify-content: center;
    align-items: center;
}
#start-stt:hover:not(:disabled), #stop-stt:hover:not(:disabled) {
     background-color: #5a6268;
}

#send-button {
    border-radius: 20px; /* ë‘¥ê·¼ ë²„íŠ¼ */
    padding: 10px 18px;
}
"""

# *** JavaScript ìˆ˜ì • ë¶€ë¶„ ì‹œì‘ ***
JAVASCRIPT_CONTENT = """
document.addEventListener('DOMContentLoaded', () => {
    // DOM ìš”ì†Œ ê°€ì ¸ì˜¤ê¸°
    const webcamVideo = document.getElementById('webcam');
    const canvas = document.getElementById('canvas');
    const context = canvas.getContext('2d', { willReadFrequently: true });
    const chatbox = document.getElementById('chatbox');
    const textInput = document.getElementById('text-input');
    const sendButton = document.getElementById('send-button');
    const sttStatus = document.getElementById('stt-status');
    const startSttButton = document.getElementById('start-stt');
    const stopSttButton = document.getElementById('stop-stt');
    const ttsAudio = document.getElementById('tts-audio');
    const connectDisconnectButton = document.getElementById('connect-disconnect'); // ì—°ê²°/í•´ì œ ë²„íŠ¼
    const observeButton = document.getElementById('start-stop-observe'); // ê´€ì°° ì‹œì‘/ì¤‘ì§€ ë²„íŠ¼
    const statusMessage = document.getElementById('status-message');

    // ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
    let socket = null;
    let mediaStream = null;
    let observeInterval = null; // ì£¼ê¸°ì  ê´€ì°° ì¸í„°ë²Œ ID
    let latestFrameDataBase64 = null;
    const OBSERVE_INTERVAL_MS = 5000; // ê´€ì°° ê°„ê²©
    let isConnected = false; // WebSocket ì—°ê²° ìƒíƒœ
    let isObserving = false; // ì£¼ê¸°ì  ê´€ì°° ì‹¤í–‰ ìƒíƒœ

    // --- ìƒíƒœ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ ---
    function setStatusMessage(message) {
        if (statusMessage) {
            statusMessage.textContent = `ìƒíƒœ: ${message}`;
        }
        console.log(`Status: ${message}`);
    }

    // --- UI ìš”ì†Œ í™œì„±í™”/ë¹„í™œì„±í™” í•¨ìˆ˜ ---
    function updateUIState() {
        // ì—°ê²° ë²„íŠ¼ í…ìŠ¤íŠ¸ ë³€ê²½
        connectDisconnectButton.textContent = isConnected ? "ì„œë²„ ì—°ê²° í•´ì œ" : "ì„œë²„ ì—°ê²°";

        // ê´€ì°° ë²„íŠ¼ í™œì„±í™”/ë¹„í™œì„±í™” ë° í…ìŠ¤íŠ¸ ë³€ê²½
        observeButton.disabled = !isConnected; // ì—°ê²° ìƒíƒœì¼ ë•Œë§Œ í™œì„±í™”
        observeButton.textContent = isObserving ? "ê´€ì°° ì¤‘ì§€" : "ê´€ì°° ì‹œì‘";

        // ì…ë ¥ ê´€ë ¨ ìš”ì†Œ í™œì„±í™”/ë¹„í™œì„±í™”
        textInput.disabled = !isConnected;
        sendButton.disabled = !isConnected;
        startSttButton.disabled = !isConnected;
        // stopSttButtonì€ isRecognizing ìƒíƒœì— ë”°ë¼ ë³„ë„ ê´€ë¦¬ë¨

        // ìƒíƒœ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸ (ì˜ˆ: ì—°ê²° ìƒíƒœ ë°˜ì˜)
        if (!isConnected) {
            setStatusMessage("ì¤€ë¹„ë¨. 'ì„œë²„ ì—°ê²°' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.");
        } else if (isObserving) {
            setStatusMessage("ì—°ê²°ë¨ - ì£¼ê¸°ì ìœ¼ë¡œ ê´€ì°° ì¤‘...");
        } else {
            setStatusMessage("ì—°ê²°ë¨ - ëŒ€ê¸° ì¤‘.");
        }
    }


    // --- WebSocket í†µì‹  í•¨ìˆ˜ ---
    function connectWebSocket() {
        if (socket) return; // ì´ë¯¸ ì—°ê²°ë˜ì–´ ìˆê±°ë‚˜ ì—°ê²° ì‹œë„ ì¤‘ì´ë©´ ë¬´ì‹œ

        const wsProtocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
        const wsUrl = `${wsProtocol}//${window.location.host}/ws`;
        setStatusMessage("ì„œë²„ ì—°ê²° ì‹œë„ ì¤‘...");
        connectDisconnectButton.disabled = true; // ì—°ê²° ì‹œë„ ì¤‘ ë²„íŠ¼ ë¹„í™œì„±í™”

        socket = new WebSocket(wsUrl);

        socket.onopen = () => {
            console.log("WebSocket connection established.");
            isConnected = true; // ì—°ê²° ìƒíƒœ ì—…ë°ì´íŠ¸
            connectDisconnectButton.disabled = false; // ë²„íŠ¼ ë‹¤ì‹œ í™œì„±í™”
            updateUIState(); // UI ìƒíƒœ ì—…ë°ì´íŠ¸
            addMessage("System", "Auraì™€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.");
            // ì›¹ìº  ì‹œì‘ ì‹œë„ (ì—°ê²° ì„±ê³µ í›„)
            startWebcam();
        };

        socket.onmessage = (event) => { // ë©”ì‹œì§€ ìˆ˜ì‹  ì²˜ë¦¬ (ë³€ê²½ ì—†ìŒ)
            try {
                const data = JSON.parse(event.data);
                console.log("Message from server:", data);
                if (data.type === "response") {
                    addMessage("Aura", data.ai_text);
                    if (data.audio_url) playTTS(data.audio_url);
                } else if (data.type === "error") {
                     addMessage("System", `ì„œë²„ ì˜¤ë¥˜: ${data.message}`);
                     setStatusMessage(`ì„œë²„ ì˜¤ë¥˜: ${data.message}`);
                }
            } catch (error) {
                console.error("Failed to parse or handle server message:", error);
                addMessage("System", "ì„œë²„ ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ");
            }
        };

        socket.onerror = (error) => {
            console.error("WebSocket error:", error);
            addMessage("System", "WebSocket ì˜¤ë¥˜ ë°œìƒ. ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.");
            isConnected = false; // ì—°ê²° ìƒíƒœ ì—…ë°ì´íŠ¸
            connectDisconnectButton.disabled = false; // ë²„íŠ¼ ë‹¤ì‹œ í™œì„±í™”
            stopWebcam(); // ì›¹ìº  ì¤‘ì§€
            stopObserveInterval(); // ê´€ì°° ì¸í„°ë²Œ ì¤‘ì§€
            updateUIState(); // UI ì—…ë°ì´íŠ¸
            socket = null; // ì†Œì¼“ ê°ì²´ ì •ë¦¬
        };

        socket.onclose = (event) => {
            console.log("WebSocket connection closed:", event.reason, `Code: ${event.code}`);
            const wasConnected = isConnected; // ì—°ê²° í•´ì œ ì „ ìƒíƒœ ì €ì¥
            isConnected = false; // ì—°ê²° ìƒíƒœ ì—…ë°ì´íŠ¸
            connectDisconnectButton.disabled = false; // ë²„íŠ¼ ë‹¤ì‹œ í™œì„±í™”
            stopWebcam();
            stopObserveInterval();
            updateUIState();
            socket = null;
            if (wasConnected) { // ì´ì „ì— ì—°ê²°ë˜ì–´ ìˆì—ˆë‹¤ë©´ ë©”ì‹œì§€ í‘œì‹œ
                 addMessage("System", "Auraì™€ ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.");
            }
        };
    }

    function disconnectWebSocket() {
        if (socket) {
            setStatusMessage("ì—°ê²° í•´ì œ ì¤‘...");
            socket.close(); // onclose í•¸ë“¤ëŸ¬ì—ì„œ ìµœì¢… ì •ë¦¬ ìˆ˜í–‰
        }
        // ì›¹ìº  ë° ê´€ì°°ë„ í•¨ê»˜ ì¤‘ì§€
        stopWebcam();
        stopObserveInterval();
        updateUIState(); // UI ì¦‰ì‹œ ì—…ë°ì´íŠ¸
    }

    // --- ì›¹ìº  ì²˜ë¦¬ í•¨ìˆ˜ ---
    async function startWebcam() {
        if (mediaStream) return true; // ì´ë¯¸ ì‹œì‘ë˜ì–´ ìˆìœ¼ë©´ true ë°˜í™˜

        setStatusMessage("ì›¹ìº  ì‹œì‘ ì¤‘...");
        try {
             mediaStream = await navigator.mediaDevices.getUserMedia({
                video: { width: { ideal: 640 }, height: { ideal: 480 } },
                audio: false
             });
            webcamVideo.srcObject = mediaStream;
            await webcamVideo.play();

            return new Promise((resolve) => {
                webcamVideo.onloadedmetadata = () => {
                     canvas.width = webcamVideo.videoWidth;
                     canvas.height = webcamVideo.videoHeight;
                     console.log(`Webcam started: ${canvas.width}x${canvas.height}`);
                     setStatusMessage(isObserving ? "ì—°ê²°ë¨ - ì£¼ê¸°ì ìœ¼ë¡œ ê´€ì°° ì¤‘..." : "ì—°ê²°ë¨ - ëŒ€ê¸° ì¤‘."); // ì›¹ìº  ì„±ê³µ ì‹œ ì—°ê²° ìƒíƒœ ë°˜ì˜
                     resolve(true);
                };
                 webcamVideo.onerror = (e) => {
                     console.error("Webcam video element error:", e);
                     setStatusMessage("ì›¹ìº  ë¹„ë””ì˜¤ í‘œì‹œ ì˜¤ë¥˜.");
                     resolve(false);
                 }
            });
        } catch (err) {
            console.error("Error accessing webcam:", err);
            let errorMsg = err.message;
            if (err.name === "NotAllowedError") errorMsg = "ì›¹ìº  ì ‘ê·¼ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.";
            else if (err.name === "NotFoundError") errorMsg = "ì—°ê²°ëœ ì›¹ìº ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.";
            addMessage("System", `ì›¹ìº  ì ‘ê·¼ ì˜¤ë¥˜: ${errorMsg}.`);
            setStatusMessage(`ì›¹ìº  ì˜¤ë¥˜: ${errorMsg}`);
            return false;
        }
    }

    function stopWebcam() {
        if (mediaStream) {
            mediaStream.getTracks().forEach(track => track.stop());
            mediaStream = null;
            webcamVideo.srcObject = null;
            console.log("Webcam stopped.");
            // ìƒíƒœ ë©”ì‹œì§€ëŠ” updateUIState ë˜ëŠ” disconnectWebSocketì—ì„œ ê´€ë¦¬
        }
    }

    // --- í”„ë ˆì„ ìº¡ì²˜ ë° ì „ì†¡ í•¨ìˆ˜ ---
    function captureFrame() {
        if (!mediaStream || !webcamVideo.videoWidth || webcamVideo.paused || webcamVideo.ended) {
            console.warn("Webcam not ready for capture.");
            latestFrameDataBase64 = null;
            return;
        };
        try {
            context.drawImage(webcamVideo, 0, 0, canvas.width, canvas.height);
            latestFrameDataBase64 = canvas.toDataURL('image/jpeg', 0.7);
        } catch (e) {
            console.error("Error capturing frame:", e);
            latestFrameDataBase64 = null;
        }
    }

    // í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ í˜„ì¬ í”„ë ˆì„ì„ ì„œë²„ë¡œ ì „ì†¡ (ì—°ê²° ìƒíƒœ í™•ì¸ í•„ìˆ˜)
    async function sendFrameAndText(text = "") {
        if (!isConnected || !socket || socket.readyState !== WebSocket.OPEN) {
            addMessage("System", "ì„œë²„ì— ì—°ê²°ë˜ì–´ ìˆì§€ ì•Šì•„ ë©”ì‹œì§€ë¥¼ ë³´ë‚¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
            console.warn("Attempted to send data while disconnected.");
            return; // ì—°ê²° ì•ˆë˜ì–´ ìˆìœ¼ë©´ ì „ì†¡ ì•ˆí•¨
        }

        // ì›¹ìº ì´ ì¼œì ¸ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì•ˆ ì¼œì ¸ ìˆë‹¤ë©´ ì‹œì‘ ì‹œë„
        if (!mediaStream) {
            const webcamStarted = await startWebcam();
            if (!webcamStarted) {
                 addMessage("System", "ì›¹ìº ì„ ì‹œì‘í•  ìˆ˜ ì—†ì–´ ì´ë¯¸ì§€ ì—†ì´ í…ìŠ¤íŠ¸ë§Œ ì „ì†¡í•©ë‹ˆë‹¤.");
                 latestFrameDataBase64 = null; // ì´ë¯¸ì§€ ì—†ìŒì„ ëª…ì‹œ
            } else {
                 // ì›¹ìº  ì‹œì‘ í›„ ì ì‹œ ê¸°ë‹¤ë ¸ë‹¤ê°€ ìº¡ì²˜ (í•„ìš”ì‹œ)
                 await new Promise(resolve => setTimeout(resolve, 200)); // 0.2ì´ˆ ëŒ€ê¸°
                 captureFrame();
            }
        } else {
             captureFrame(); // ì›¹ìº  ì¼œì ¸ ìˆìœ¼ë©´ ë°”ë¡œ ìº¡ì²˜
        }


        // í”„ë ˆì„ ìº¡ì²˜ ì„±ê³µ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ì¼ë‹¨ í˜ì´ë¡œë“œ êµ¬ì„±
        const payload = {
            image: latestFrameDataBase64, // nullì¼ ìˆ˜ë„ ìˆìŒ
            text: text
        };

        try {
            socket.send(JSON.stringify(payload));
            console.log(`Sent data (text: ${text ? text.substring(0,20)+'...' : '[observe]'}, image: ${latestFrameDataBase64 ? 'Yes' : 'No'})`);
        } catch (e) {
            console.error("Error sending data via WebSocket:", e);
            addMessage("System", "ë°ì´í„° ì „ì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ.");
            // ì—°ê²° ì˜¤ë¥˜ ì‹œ onerror í•¸ë“¤ëŸ¬ê°€ ì²˜ë¦¬í•  ê²ƒì„
        }
    }

    // --- ì£¼ê¸°ì  ê´€ì°° ì œì–´ ---
    function startObserveInterval() {
        if (observeInterval) return; // ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ë¬´ì‹œ
        if (!isConnected) return; // ì—°ê²° ì•ˆë˜ì–´ ìˆìœ¼ë©´ ì‹œì‘ ì•ˆí•¨

        console.log("Starting observe interval...");
        isObserving = true;
        observeButton.textContent = "ê´€ì°° ì¤‘ì§€"; // ë²„íŠ¼ í…ìŠ¤íŠ¸ ë³€ê²½
        setStatusMessage("ì—°ê²°ë¨ - ì£¼ê¸°ì ìœ¼ë¡œ ê´€ì°° ì¤‘...");

        // ì•½ê°„ì˜ ì§€ì—° í›„ ì²« ê´€ì°° ì‹œì‘
        setTimeout(() => {
            if (isObserving) sendFrameAndText(""); // ê´€ì°° ìƒíƒœì¼ ë•Œë§Œ ì „ì†¡
        }, 500);

        observeInterval = setInterval(() => {
            if (isObserving && isConnected) { // ê´€ì°° ì¤‘ì´ê³  ì—°ê²° ìƒíƒœì¼ ë•Œë§Œ ì „ì†¡
                sendFrameAndText("");
            } else {
                // ê´€ì°° ì¤‘ì§€ ë˜ëŠ” ì—°ê²° ëŠê¹€ ì‹œ ì¸í„°ë²Œ ìë™ ì¤‘ì§€
                stopObserveInterval();
            }
        }, OBSERVE_INTERVAL_MS);
    }

    function stopObserveInterval() {
        if (observeInterval) {
            clearInterval(observeInterval);
            observeInterval = null;
            isObserving = false;
            if (isConnected) { // ì—°ê²° ìƒíƒœì¼ ë•Œë§Œ UI ì—…ë°ì´íŠ¸
                 observeButton.textContent = "ê´€ì°° ì‹œì‘";
                 setStatusMessage("ì—°ê²°ë¨ - ëŒ€ê¸° ì¤‘.");
            }
            console.log("Observe interval stopped.");
        }
         // isObserving í”Œë˜ê·¸ëŠ” ì—¬ê¸°ì„œ falseë¡œ ì„¤ì •
         isObserving = false;
         if (isConnected) {
             observeButton.textContent = "ê´€ì°° ì‹œì‘"; // ë²„íŠ¼ í…ìŠ¤íŠ¸ ë³µêµ¬
         }
    }

    // --- ì±„íŒ… ë° TTS í•¨ìˆ˜ (ë³€ê²½ ì—†ìŒ) ---
    function addMessage(sender, text) {
        const messageElement = document.createElement('div');
        messageElement.classList.add('message', sender.toLowerCase());
        messageElement.innerHTML = `<strong>${sender}:</strong> ${text}`;
        chatbox.appendChild(messageElement);
        chatbox.scrollTop = chatbox.scrollHeight;
    }

    function playTTS(audioUrl) {
        if (ttsAudio && audioUrl) {
            ttsAudio.src = audioUrl;
            ttsAudio.play().catch(e => {
                console.error("Audio playback error:", e);
                addMessage("System", "ì˜¤ë””ì˜¤ ìë™ ì¬ìƒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
            });
        }
    }

    // --- STT (Web Speech API) (ë³€ê²½ ì—†ìŒ) ---
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    let recognition = null;
    let isRecognizing = false;

    if (SpeechRecognition) {
        recognition = new SpeechRecognition();
        recognition.continuous = false;
        recognition.lang = 'ko-KR';
        recognition.interimResults = false;
        recognition.maxAlternatives = 1;

        recognition.onstart = () => {
            isRecognizing = true;
            sttStatus.textContent = "ë“£ê³  ìˆìŠµë‹ˆë‹¤...";
            startSttButton.disabled = true;
            stopSttButton.disabled = false;
        };

        recognition.onresult = (event) => {
            const transcript = event.results[0][0].transcript;
            sttStatus.textContent = `ì¸ì‹ë¨: ${transcript}`;
            textInput.value = transcript;
            // ì¸ì‹ í›„ ìë™ ì „ì†¡? ì„ íƒ ì‚¬í•­
            // sendUserInput();
        };

        recognition.onerror = (event) => {
            console.error("Speech recognition error:", event.error, event.message);
            let errorMsg = event.error;
            if (event.error === 'no-speech') errorMsg = "ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.";
            else if (event.error === 'audio-capture') errorMsg = "ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜.";
            else if (event.error === 'not-allowed') errorMsg = "ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.";
            else errorMsg = event.message || event.error;
             sttStatus.textContent = `ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ${errorMsg}`;
        };

        recognition.onend = () => {
            isRecognizing = false;
            if (sttStatus.textContent === "ë“£ê³  ìˆìŠµë‹ˆë‹¤...") sttStatus.textContent = "ìŒì„± ì…ë ¥ ì¢…ë£Œë¨.";
            else if (!sttStatus.textContent.includes("ì˜¤ë¥˜")) sttStatus.textContent = "ìŒì„± ì…ë ¥ ì¢…ë£Œë¨.";
            startSttButton.disabled = false;
            stopSttButton.disabled = true;
            console.log("Speech recognition ended.");
        };

    } else {
        sttStatus.textContent = "ìŒì„± ì¸ì‹ì´ ì§€ì›ë˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.";
        startSttButton.disabled = true;
        stopSttButton.disabled = true;
    }

    function startStt() {
        // *** ì—°ê²° ìƒíƒœ í™•ì¸ì€ ë¶ˆí•„ìš” (ì–¸ì œë“  ì‹œë„ ê°€ëŠ¥) ***
        // if (!isConnected) {
        //     addMessage("System", "ì„œë²„ì— ì—°ê²°ë˜ì–´ ìˆì„ ë•Œ ìŒì„± ì¸ì‹ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.");
        //     return;
        // }
        if (recognition && !isRecognizing) {
            try { recognition.start(); }
            catch(e) { console.error("STT start error:", e); sttStatus.textContent = "STT ì‹œì‘ ì˜¤ë¥˜."; }
        }
    }

    function stopStt() {
        if (recognition && isRecognizing) {
             try { recognition.stop(); }
             catch(e) {
                 console.error("STT stop error:", e); sttStatus.textContent = "STT ì¤‘ì§€ ì˜¤ë¥˜.";
                 isRecognizing = false; startSttButton.disabled = false; stopSttButton.disabled = true; // ìˆ˜ë™ ë³µêµ¬
             }
        }
    }

    // --- ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜ ---
    async function sendUserInput() { // async ì¶”ê°€ for await startWebcam
        // *** ì—°ê²° ìƒíƒœ í™•ì¸ì€ sendFrameAndText ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ ***
        // if (!isConnected) {
        //      addMessage("System", "ì„œë²„ì— ì—°ê²°ë˜ì–´ ìˆì§€ ì•Šì•„ ë©”ì‹œì§€ë¥¼ ë³´ë‚¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
        //      return;
        // }
        const text = textInput.value.trim();
        if (text) {
            addMessage("User", text); // UIì— ë¨¼ì € í‘œì‹œ
            await sendFrameAndText(text); // ì„œë²„ë¡œ ì „ì†¡ (await ì¶”ê°€)
            textInput.value = "";     // ì…ë ¥ì°½ ì´ˆê¸°í™”
        } else {
            // í…ìŠ¤íŠ¸ ì—†ì´ ì „ì†¡ ì‹œ ê´€ì°° ìš”ì²­
             addMessage("System", "(í˜„ì¬ ì¥ë©´ì„ ì‚´í´ë´ ë‹¬ë¼ê³  ìš”ì²­í•©ë‹ˆë‹¤...)");
             await sendFrameAndText(""); // await ì¶”ê°€
        }
        textInput.focus();
    }

    // --- ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì„¤ì • ---
    // ì—°ê²°/í•´ì œ ë²„íŠ¼ í† ê¸€
    connectDisconnectButton.addEventListener('click', () => {
        if (isConnected) {
            disconnectWebSocket();
        } else {
            connectWebSocket();
        }
    });

    // ê´€ì°° ì‹œì‘/ì¤‘ì§€ ë²„íŠ¼ í† ê¸€
    observeButton.addEventListener('click', () => {
        if (isObserving) {
            stopObserveInterval();
        } else {
            startObserveInterval();
        }
    });

    sendButton.addEventListener('click', sendUserInput);
    textInput.addEventListener('keypress', (event) => {
        if (event.key === 'Enter' && !event.shiftKey) {
             event.preventDefault();
            sendUserInput();
        }
    });
    startSttButton.addEventListener('click', startStt);
    stopSttButton.addEventListener('click', stopStt);

    // --- ì´ˆê¸°í™” ---
    updateUIState(); // ì´ˆê¸° UI ìƒíƒœ ì„¤ì •
    addMessage("System", "'ì„œë²„ ì—°ê²°' ë²„íŠ¼ì„ ëˆŒëŸ¬ Auraë¥¼ í™œì„±í™”í•˜ì„¸ìš”.");

    // í˜ì´ì§€ ì¢…ë£Œ ì‹œ ì •ë¦¬
    window.addEventListener('beforeunload', () => {
        disconnectWebSocket(); // ì›¹ì†Œì¼“ ì—°ê²° í•´ì œ ì‹œë„
    });
});
"""
# *** JavaScript ìˆ˜ì • ë¶€ë¶„ ë ***

# --- FastAPI App Setup (ë³€ê²½ ì—†ìŒ) ---
app = fastapi.FastAPI()

# --- Helper Functions (generate_tts, cleanup_old_audio_files, call_ollama_gemma3 - ë³€ê²½ ì—†ìŒ) ---
async def generate_tts(text: str) -> str | None:
    try:
        output_filename = f"aura_tts_{uuid.uuid4()}.mp3"
        output_path = AUDIO_DIR / output_filename
        communicate = edge_tts.Communicate(text, TTS_VOICE)
        await communicate.save(str(output_path))
        audio_url = f"/static/audio/{output_filename}"
        print(f"TTS generated: {audio_url}")
        asyncio.create_task(cleanup_old_audio_files(max_age_seconds=600))
        return audio_url
    except Exception as e:
        print(f"Error generating TTS: {e}")
        return None

async def cleanup_old_audio_files(max_age_seconds: int):
    try:
        now = time.time()
        removed_count = 0
        for filename in os.listdir(AUDIO_DIR):
            if filename.endswith(".mp3"):
                file_path = AUDIO_DIR / filename
                try:
                    if now - file_path.stat().st_mtime > max_age_seconds:
                        os.remove(file_path)
                        removed_count += 1
                except OSError as e:
                    print(f"Error removing file {filename}: {e}")
        if removed_count > 0:
            print(f"Cleaned up {removed_count} old audio file(s).")
    except Exception as e:
        print(f"Error during audio cleanup task: {e}")

async def call_ollama_gemma3(image_base64: str | None, text: str, history: list) -> str:
    full_prompt = SYSTEM_CONTEXT
    for turn in history[-4:]: # ìµœê·¼ 2í„´ (ì‚¬ìš©ì+ëª¨ë¸)
        role = turn.get('role', 'user')
        full_prompt += f"<start_of_turn>{role}\n{turn['content']}<end_of_turn>\n"

    user_content = text if text else "(Observing the scene)"
    full_prompt += f"<start_of_turn>user\n{user_content}<end_of_turn>\n"
    full_prompt += "<start_of_turn>model\n"

    payload = {
        "model": MODEL_NAME,
        "prompt": full_prompt,
        "stream": False,
        "options": {
            "num_predict": 100,
            "temperature": 0.7,
            "stop": ["<end_of_turn>"]
        }
    }
    # ì´ë¯¸ì§€ ë°ì´í„° ì²˜ë¦¬ ê°•í™”
    if image_base64:
        if "," in image_base64:
             try:
                 image_base64_data = image_base64.split(",")[1]
                 payload["images"] = [image_base64_data]
             except IndexError:
                 print("Warning: Invalid base64 image format received (IndexError). Image ignored.")
        else:
             # ë°ì´í„° URI ìŠ¤í‚¤ë§ˆê°€ ì—†ëŠ” ìˆœìˆ˜ base64 ë¬¸ìì—´ì¼ ê²½ìš°
             payload["images"] = [image_base64]
    else:
         print("No image data received for this request.")


    try:
        print(f"Sending prompt to Ollama (approx length: {len(full_prompt)})")
        response = await asyncio.to_thread(
            requests.post, OLLAMA_API_URL, json=payload, timeout=90
        )
        response.raise_for_status()
        response_data = response.json()
        ai_response = response_data.get("response", "").strip()

        if "<end_of_turn>" in ai_response:
             ai_response = ai_response.split("<end_of_turn>")[0].strip()
        if ai_response.startswith("model\n"):
            ai_response = ai_response[len("model\n"):].strip()

        print(f"Ollama response: {ai_response}")
        # Update history only on successful response
        history.append({"role": "user", "content": user_content})
        history.append({"role": "model", "content": ai_response})

        return ai_response if ai_response else "(Auraê°€ ì•„ë¬´ ë§ë„ í•˜ì§€ ì•Šì•˜ì–´ìš”.)"

    except requests.exceptions.Timeout:
        print("Ollama API call timed out.")
        return "(Auraê°€ ì‘ë‹µí•˜ëŠ” ë° ì‹œê°„ì´ ì¢€ ê±¸ë¦¬ë„¤ìš”... ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.)"
    except requests.exceptions.RequestException as e:
        print(f"Ollama API request error: {e}")
        return f"(Ollama ì„œë²„ì™€ í†µì‹  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e})"
    except Exception as e:
        print(f"Error processing Ollama response: {e}")
        return "(ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.)"

# --- WebSocket Connection Manager (ë³€ê²½ ì—†ìŒ) ---
class ConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []
        self.history: dict[WebSocket, list] = {}

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
        self.history[websocket] = []
        print(f"WebSocket connected: {websocket.client}")

    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
        if websocket in self.history:
            del self.history[websocket]
        print(f"WebSocket disconnected: {websocket.client}")

    async def send_json(self, message: dict, websocket: WebSocket):
        if websocket in self.active_connections:
             try:
                 await websocket.send_json(message)
             except Exception as e:
                 print(f"Failed to send message to {websocket.client}: {e}")
                 self.disconnect(websocket) # ì „ì†¡ ì‹¤íŒ¨ ì‹œ ì—°ê²° í•´ì œ
        else:
             print(f"Attempted to send to disconnected client: {websocket.client}")

manager = ConnectionManager()

# --- API Endpoints (ë³€ê²½ ì—†ìŒ) ---
@app.get("/static/css/style.css", response_class=Response)
async def get_css():
    return Response(content=CSS_CONTENT, media_type="text/css")

@app.get("/static/js/main.js", response_class=Response)
async def get_js():
    return Response(content=JAVASCRIPT_CONTENT, media_type="application/javascript")

@app.get("/", response_class=HTMLResponse)
async def get_root():
    return HTMLResponse(content=HTML_CONTENT)

app.mount("/static/audio", StaticFiles(directory=AUDIO_DIR), name="static_audio")


@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        while True:
            data = await websocket.receive_json()
            image_base64 = data.get("image")
            user_text = data.get("text", "") # ë¹ˆ ë¬¸ìì—´ì´ ê¸°ë³¸ê°’ (ê´€ì°°)

            current_history = manager.history.get(websocket, [])

            ai_response_text = await call_ollama_gemma3(image_base64, user_text, current_history)

            audio_url = await generate_tts(ai_response_text)

            response_payload = {
                "type": "response",
                "ai_text": ai_response_text,
                "audio_url": audio_url
            }
            await manager.send_json(response_payload, websocket)

    except WebSocketDisconnect:
        manager.disconnect(websocket)
        print(f"Client {websocket.client} disconnected gracefully.")
    except Exception as e:
        print(f"WebSocket Error for {websocket.client}: {e}")
        error_payload = {"type": "error", "message": f"Server error processing request."}
        await manager.send_json(error_payload, websocket)
        manager.disconnect(websocket)


# --- Uvicorn ì‹¤í–‰ (ë³€ê²½ ì—†ìŒ) ---
if __name__ == "__main__":
    print("Starting FastAPI server...")
    print(f"Audio files will be saved in: {AUDIO_DIR.resolve()}")
    print("Access the application at http://localhost:8000")
    uvicorn.run(app, host="0.0.0.0", port=8000)
    # For development: uvicorn main:app --reload
